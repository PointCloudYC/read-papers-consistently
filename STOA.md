# STOA


## CapsNet


### refs
* [[1906.06818] Stacked Capsule Autoencoders](https://arxiv.org/abs/1906.06818)
* [google-research/stacked_capsule_autoencoders at master · google-research/google-research · GitHub](https://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders)
* [Stacked Capsule Autoencoders](http://akosiorek.github.io/ml/2019/06/23/stacked_capsule_autoencoders.html)
* [三巨头共聚AAAI：Capsule没有错，LeCun看好自监督，Bengio谈注意力](https://mp.weixin.qq.com/s/nDDAx6AB9SYgQ9cVevjZvA)


## Self-supervised learning (SSL)

### refs
* [三巨头共聚AAAI：Capsule没有错，LeCun看好自监督，Bengio谈注意力](https://mp.weixin.qq.com/s/nDDAx6AB9SYgQ9cVevjZvA)


## Attention mechnism

### refs
* [三巨头共聚AAAI：Capsule没有错，LeCun看好自监督，Bengio谈注意力](https://mp.weixin.qq.com/s/nDDAx6AB9SYgQ9cVevjZvA)


## AUtoDL

### refs
[Automated Deep Learning: Theory, Algorithms, Platforms, and Applications](http://baiduautodl.com/)
[干货教程！百度AutoDL「自动深度学习: 理论、算法、平台和应用」132PPT](https://mp.weixin.qq.com/s/UB39kvBGXZxGsRjv451tew)