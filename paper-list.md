[TOC]

# Read papers consistently

a curated list of to-read papers on deep learning.

**Why doing things consistently is a a good habit?**

- simple answer is **accomplish anything you want.**
- For more, you can check the below inspiring articles. 
  - [5 Reasons Why Consistency is an Important Habit | Neel Raman](https://neelraman.com/5-reasons-why-consistency-is-an-important-habit/), 
  - [Why You MUST Do The Little Things Consistently - David Horsager](https://davidhorsager.com/why-you-must-do-the-little-things-consistently/),

## review papers

- Schmidhuber, “Deep Learning in Neural Networks” 
- Domingos, “A Few Useful Things to Know about Machine Learning” 
- Hinton, “[Top]Reducing the Dimensionality of Data with Neural Networks” 
- Halevy, Norvig, and Pereira, “[Top]The Unreasonable Effectiveness of Data”
- Bengio, Courville, and Vincent, “Representation Learning” 
- Jordan and Mitchell, “Machine Learning” 
- Hamilton, Ying, and Leskovec, “Representation Learning on Graphs” 

## classic foundational papers

- LeCun, Bengio, and Hinton, “1-Deep Learning”
- Krizhevsky, Sutskever, and Hinton, “2-ImageNet Classification with Deep Convolutional Neural Networks”
- He et al., “3-Deep Residual Learning for Image Recognition”
- Lecun et al., “4-Gradient-Based Learning Applied to Document Recognition”
- “5 Reasons Why Consistency Is an Important Habit”
- Szegedy et al., “5-Going Deeper with Convolutions”;
- Simonyan and Zisserman, “6-Very Deep Convolutional Networks for Large-Scale Image Recognition”
- Lin, Chen, and Yan, “7-Network In Network”
- Chollet, “Xception”
- Huang et al., “8-Densely Connected Convolutional Networks”
- Szegedy et al., “9-Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning”
- Goodfellow et al., “10-Generative Adversarial Networks”
- Kingma and Ba, “Adam”; 
- Ioffe and Szegedy, “Batch Normalization” 
- Srivastava et al., “Dropout: A Simple Way to Prevent Neural Networks from Overﬁtting”
- Zeiler and Fergus, “Visualizing and Understanding Convolutional Networks.”
- [Xception](http://openaccess.thecvf.com/content_cvpr_2017/html/Chollet_Xception_Deep_Learning_CVPR_2017_paper.html)
- [Network In Network](https://arxiv.org/abs/1312.4400), [network in network review](https://github.com/PointCloudYC/read-papers-consistently/nin.md)
- [Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition](https://arxiv.org/abs/1406.4729)
- [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Visualizing and Understanding Convolutional Networks | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53)
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)

## advanced papers

- Jaderberg et al., “Spatial Transformer Networks”
- Chen et al., “Drop an Octave”
- Xu, Evans, and Qi, “Feature Squeezing”Szegedy et al., “9-Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning”
- Hinton, Osindero, and Teh, “A Fast Learning Algorithm for Deep Belief Nets”
- Liu et al., “An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution”
- Marcus, “Deep Learning”
- Hinton, Vinyals, and Dean, “Distilling the Knowledge in a Neural Network”
- Selvaraju et al., “Grad-CAM”Vedaldi and Lenc, “MatConvNet”
- Szegedy et al., “Rethinking the Inception Architecture for Computer Vision”
- Zamir et al., “Taskonomy”
- Bengio, “[Top]Practical Recommendations for Gradient-Based Training of Deep Architectures”
- Glorot and Bengio, “[Top]Understanding the Difﬁculty of Training Deep Feedforward Neural Networks”
- Tremblay et al., “Training Deep Networks with Synthetic Data”
- Cheng et al., “Wide & Deep Learning for Recommender Systems.”


## Point cloud processing Using DL

### PC Segmentation and classfication

* [splatnet: SPLATNet: Sparse Lattice Networks for Point Cloud Processing (CVPR2018)](https://github.com/NVlabs/splatnet)
* [SO-Net: SO-Net: Self-Organizing Network for Point Cloud Analysis, CVPR2018](https://github.com/lijx10/SO-Net)
* [fully-convolutional-point-network: Fully-Convolutional Point Networks for Large-Scale Point Clouds](https://github.com/drethage/fully-convolutional-point-network)
* [superpoint_graph: Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs](https://github.com/loicland/superpoint_graph)
* [depth clustering](https://github.com/PRBonn/depth_clustering)
* [3d-semantic-segmentation: This work is based on our paper Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds, which is appeared at the IEEE International Conference on Computer Vision (ICCV) 2017, 3DRMS Workshop.](https://github.com/VisualComputingInstitute/3d-semantic-segmentation)

### PC Detection

* [Class-balanced-Grouping-and-Sampling-for-Point-Cloud-3D-Object-Detection: Winner's Code and Technical Report for the nuScenes 3D Object Detection challenge in WAD, CVPR 2019](https://github.com/poodarchu/Class-balanced-Grouping-and-Sampling-for-Point-Cloud-3D-Object-Detection)
* PointPillar
* [ApproxMVBB: Fast algorithms to compute an approximation of the minimal volume oriented bounding box of a point cloud in 3D.](https://github.com/gabyx/ApproxMVBB), approximation of the bounding box which is useful for the detection task.
* [3D_CNN_tensorflow: KITTI data processing and 3D CNN for Vehicle Detection](https://github.com/yukitsuji/3D_CNN_tensorflow)

### Other(registration,etc.)
* [learning_to_sample: A learned sampling approach for point clouds (CVPR 2019)](https://github.com/orendv/learning_to_sample), FPS vs the learning_to_sample
* [Super4PCS: Efficient Global Point-cloud registration](https://github.com/nmellado/Super4PCS)

## Group papers
### MA Jun
all the paper summaries are in [summaries](https://github.com/PointCloudYC/read-papers-consistently/blob/master/summaries/MAJun/summaries.md)



- Ma, Jun, and Jack C. P. Cheng. “Identifying the Influential Features on the Regional Energy Use Intensity of Residential Buildings Based on Random Forests.” Applied Energy 183 (December 1, 2016)

- Ma, Jun, and Jack C. P. Cheng.“Estimation of the Building Energy Use Intensity in the Urban Scale by Integrating GIS and Big Data Technology.” Applied Energy 183 (December 1, 2016)

- Ma, Jun, Jack C.P. Cheng, Changqing Lin, Yi Tan, and Jingcheng Zhang. “Improving Air Quality Prediction Accuracy at Larger Temporal Resolutions Using Deep Learning and Transfer Learning Techniques.” Atmospheric Environment 214 (October 2019)

- Ma, Jun, Jack C. P. Cheng, Feifeng Jiang, Weiwei Chen, and Jingcheng Zhang. “2-Analyzing Driving Factors of Land Values in Urban Scale Based on Big Data and Non-Linear Machine Learning Techniques.” Land Use Policy 94 (May 1, 2020)

- Ma, Jun, Jack C. P. Cheng, Feifeng Jiang, Vincent J. L. Gan, Mingzhu Wang, and Chong Zhai. “Real-Time Detection of Wildfire Risk Caused by Powerline Vegetation Faults Using Advanced Machine Learning Techniques.” Advanced Engineering Informatics 44 (April 1, 2020)

- Ma, Jun, Yuexiong Ding, Jack C. P. Cheng, Feifeng Jiang, and Zhiwei Wan. “1-A Temporal-Spatial Interpolation and Extrapolation Method Based on Geographic Long Short-Term Memory Neural Network for PM2.5.” Journal of Cleaner Production 237 (November 10, 2019)

- Ma, Jun, Yuexiong Ding, Jack C. P. Cheng, Feifeng Jiang, and Zherui Xu. “Soft Detection of 5-Day BOD with Sparse Matrix in City Harbor Water Using Deep Learning Techniques.” Water Research 170 (March 1, 2020): 115350. https://doi.org/10.1016/j.watres.2019.115350.
- Ma, Jun, Yuexiong Ding, Jack C. P. Cheng, Yi Tan, Vincent J. L. Gan, and Jingcheng Zhang. “1-Analyzing the Leading Causes of Traffic Fatalities Using XGBoost and Grid-Based Analysis: A City Management Perspective.” IEEE Access 7 (2019)

- Ma, Jun, Yuexiong Ding, Vincent J. L. Gan, Changqing Lin, and Zhiwei Wan. “1-Spatiotemporal Prediction of PM2.5 Concentrations at Different Time Granularities Using IDW-BLSTM.” IEEE Access 7 (2019)

- Ma, Jun, Zheng Li, Jack C. P. Cheng, Yuexiong Ding, Changqing Lin, and Zherui Xu. “Air Quality Prediction at New Stations Using Spatially Transferred Bi-Directional Long Short-Term Memory Network.” Science of The Total Environment 705 (February 25, 2020)

- Ma, Jun, Jack C. P. Cheng, Feifeng Jiang, Weiwei Chen, and Jingcheng Zhang. “2-Analyzing Driving Factors of Land Values in Urban Scale Based on Big Data and Non-Linear Machine Learning Techniques.” Land Use Policy 94 (May 1, 2020)

- Ma, Jun, Jack C. P. Cheng, Feifeng Jiang, Vincent J. L. Gan, Mingzhu Wang, and Chong Zhai. “Real-Time Detection of Wildfire Risk Caused by Powerline Vegetation Faults Using Advanced Machine Learning Techniques.” Advanced Engineering Informatics 44 (April 1, 2020)

- Ma, Jun, Yuexiong Ding, Jack C. P. Cheng, Feifeng Jiang, and Zhiwei Wan. “1-A Temporal-Spatial Interpolation and Extrapolation Method Based on Geographic Long Short-Term Memory Neural Network for PM2.5.” Journal of Cleaner Production 237 (November 10, 2019)

- Ma, Jun, Yuexiong Ding, Jack C. P. Cheng, Feifeng Jiang, and Zherui Xu. “Soft Detection of 5-Day BOD with Sparse Matrix in City Harbor Water Using Deep Learning Techniques.” Water Research 170 (March 1, 2020)

- Ma, Jun, Yuexiong Ding, Jack C. P. Cheng, Yi Tan, Vincent J. L. Gan, and Jingcheng Zhang. “1-Analyzing the Leading Causes of Traffic Fatalities Using XGBoost and Grid-Based Analysis: A City Management Perspective.” IEEE Access 7 (2019)

- Ma, Jun, Yuexiong Ding, Vincent J. L. Gan, Changqing Lin, and Zhiwei Wan. “1-Spatiotemporal Prediction of PM2.5 Concentrations at Different Time Granularities Using IDW-BLSTM.” IEEE Access 7 (2019)

- Ma, Jun, Zheng Li, Jack C. P. Cheng, Yuexiong Ding, Changqing Lin, and Zherui Xu. “Air Quality Prediction at New Stations Using Spatially Transferred Bi-Directional Long Short-Term Memory Network.” Science of The Total Environment 705 (February 25, 2020)

### WANG Qian


### Minkoo Kim

